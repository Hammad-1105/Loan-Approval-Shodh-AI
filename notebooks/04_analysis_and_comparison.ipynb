{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b65f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import d3rlpy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac319a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "d3rlpy.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afcba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/processed_loans.csv'\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "896b5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-calculating rewards\n",
    "def calculate_reward(row):\n",
    "    if row['target'] == 0: # Fully Paid\n",
    "        return row['loan_amnt'] * (row['int_rate'] / 100.0)\n",
    "    else: # Default\n",
    "        return -1.0 * row['loan_amnt']\n",
    "\n",
    "df['reward'] = df.apply(calculate_reward, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81fa586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature/Target Split\n",
    "feature_cols = df.drop(columns=['target', 'reward']).columns\n",
    "X = df[feature_cols].values\n",
    "y = df['target'].values\n",
    "rewards = df['reward'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b82d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split (Same seed as before to match Phase 2)\n",
    "X_train, X_test, y_train, y_test, r_train, r_test = train_test_split(\n",
    "    X, y, rewards, test_size=0.30, random_state=SEED, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee966947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale (Crucial: Fit on Train, Transform Test)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d5d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Test Data to Tensors \n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774eb05",
   "metadata": {},
   "source": [
    "# Loading DL & RL models for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b21cb7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanDefaultModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LoanDefaultModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.layer3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.relu1(self.layer1(x)))\n",
    "        x = self.dropout2(self.relu2(self.layer2(x)))\n",
    "        x = self.dropout3(self.relu3(self.layer3(x)))\n",
    "        return self.sigmoid(self.output(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184c2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring DL Model\n",
    "dl_model = LoanDefaultModel(X_train.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(dl_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfb832ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "181ec2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model.train()\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = dl_model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d80f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-10 20:13.58 [info     ] Signatures have been automatically determined. action_signature=Signature(dtype=[dtype('int64')], shape=[(1,)]) observation_signature=Signature(dtype=[dtype('float64')], shape=[(79,)]) reward_signature=Signature(dtype=[dtype('float64')], shape=[(1,)])\n",
      "2025-12-10 20:13.58 [info     ] Action-space has been automatically determined. action_space=<ActionSpace.DISCRETE: 2>\n",
      "2025-12-10 20:13.58 [info     ] Action size has been automatically determined. action_size=2\n"
     ]
    }
   ],
   "source": [
    "#Loading RL Agent\n",
    "cql = d3rlpy.algos.DiscreteCQLConfig().create(device=\"cpu\") \n",
    "\n",
    "dummy_actions = np.zeros(100, dtype=int)\n",
    "dummy_actions[0] = 1  \n",
    "\n",
    "cql.build_with_dataset(d3rlpy.dataset.MDPDataset(\n",
    "    observations=np.array(X_train_scaled[:100]), \n",
    "    actions=dummy_actions, \n",
    "    rewards=np.zeros(100),\n",
    "    terminals=np.ones(100)\n",
    "))\n",
    "\n",
    "cql.load_model('../models/cql_loan_agent.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c543970",
   "metadata": {},
   "source": [
    "# Divergent Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7061ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Get Predictions on TEST set\n",
    "dl_model.eval()\n",
    "with torch.no_grad():\n",
    "    dl_probs = dl_model(X_test_tensor).numpy().flatten()\n",
    "    # DL Decisions (Using your Optimized Threshold 0.25)\n",
    "    dl_decisions = (dl_probs > 0.25).astype(int) \n",
    "    dl_actions = 1 - dl_decisions # 1=Approve, 0=Deny\n",
    "\n",
    "# RL Decisions (1=Approve, 0=Deny)\n",
    "rl_actions = cql.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d3ecbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Agree on: 70.3% of cases\n"
     ]
    }
   ],
   "source": [
    "# B. Compare\n",
    "agreement = (dl_actions == rl_actions)\n",
    "print(f\"Models Agree on: {np.mean(agreement):.1%} of cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e2f9bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases where DL says APPROVE but RL says DENY: 6\n"
     ]
    }
   ],
   "source": [
    "# C. Find Divergence: DL Approves (1), RL Denies (0)\n",
    "mask_dl_yes_rl_no = (dl_actions == 1) & (rl_actions == 0)\n",
    "divergent_indices = np.where(mask_dl_yes_rl_no)[0]\n",
    "\n",
    "print(f\"Cases where DL says APPROVE but RL says DENY: {len(divergent_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40efa192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divergent Case Study\n",
      "Applicant Index: 687\n",
      "DL Probability of Default: 0.0471 (Safe < 0.25)\n",
      "RL Action: 0 (Deny)\n",
      "Actual Outcome (Target): 0 (1=Default, 0=Paid)\n",
      "Financial Consequence: $6149.50\n"
     ]
    }
   ],
   "source": [
    "# D. Inspect a specific Divergent Case where DL accepts (for the Report)\n",
    "if len(divergent_indices) > 0:\n",
    "    idx = divergent_indices[0]\n",
    "    \n",
    "    print(\"Divergent Case Study\")\n",
    "    print(f\"Applicant Index: {idx}\")\n",
    "    print(f\"DL Probability of Default: {dl_probs[idx]:.4f} (Safe < 0.25)\")\n",
    "    print(f\"RL Action: {rl_actions[idx]} (Deny)\")\n",
    "    print(f\"Actual Outcome (Target): {y_test[idx]} (1=Default, 0=Paid)\")\n",
    "    print(f\"Financial Consequence: ${r_test[idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a75ac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic Loans (DL Saved / RL Lost): 4964\n",
      "Applicant Index: 45\n",
      "DL Probability: 0.3029 (High Risk)\n",
      "RL Decision: 1 (Approved - Oops)\n",
      "Real Outcome: Defaulted\n",
      "Financial Loss: $-6000.00\n"
     ]
    }
   ],
   "source": [
    "# E. Inspect a specific Divergent Case where DL Denies (for the Report)\n",
    "\n",
    "toxic_mask = (dl_actions == 0) & (rl_actions == 1) & (y_test == 1)\n",
    "toxic_indices = np.where(toxic_mask)[0]\n",
    "\n",
    "print(f\"Toxic Loans (DL Saved / RL Lost): {len(toxic_indices)}\")\n",
    "\n",
    "if len(toxic_indices) > 0:\n",
    "    idx = toxic_indices[0] # Just grab the first one\n",
    "    loss_amount = r_test[idx] # The money we lost\n",
    "    \n",
    "    print(f\"Applicant Index: {idx}\")\n",
    "    print(f\"DL Probability: {dl_probs[idx]:.4f} (High Risk)\")\n",
    "    print(f\"RL Decision: {rl_actions[idx]} (Approved - Oops)\")\n",
    "    print(f\"Real Outcome: Defaulted\")\n",
    "    print(f\"Financial Loss: ${loss_amount:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df52d5",
   "metadata": {},
   "source": [
    "# Estimated Policy Value (EPV) Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33fc9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Rewards for DL Policy\n",
    "dl_rewards = []\n",
    "for i in range(len(X_test)):\n",
    "    if dl_actions[i] == 1: # DL Approved\n",
    "        dl_rewards.append(r_test[i])\n",
    "    else:\n",
    "        dl_rewards.append(0) # DL Denied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e99e2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Rewards for RL Policy\n",
    "rl_rewards = []\n",
    "for i in range(len(X_test)):\n",
    "    if rl_actions[i] == 1: # RL Approved\n",
    "        rl_rewards.append(r_test[i])\n",
    "    else:\n",
    "        rl_rewards.append(0) # RL Denied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3271a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "epv_dl = np.mean(dl_rewards)\n",
    "epv_rl = np.mean(rl_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fede3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics Comparison\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Deep Learning (Model 1)</th>\n",
       "      <th>RL Agent (Model 2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test Set AUC</td>\n",
       "      <td>0.741</td>\n",
       "      <td>N/A (Policy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test Set F1</td>\n",
       "      <td>0.456</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Est. Policy Value (Avg Reward)</td>\n",
       "      <td>$-273.19</td>\n",
       "      <td>$-1339.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Metric Deep Learning (Model 1) RL Agent (Model 2)\n",
       "0                    Test Set AUC                   0.741       N/A (Policy)\n",
       "1                     Test Set F1                   0.456                N/A\n",
       "2  Est. Policy Value (Avg Reward)                $-273.19          $-1339.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Test Set AUC', 'Test Set F1', 'Est. Policy Value (Avg Reward)'],\n",
    "    'Deep Learning (Model 1)': [0.741, 0.456, f\"${epv_dl:.2f}\"],\n",
    "    'RL Agent (Model 2)': ['N/A (Policy)', 'N/A', f\"${epv_rl:.2f}\"]\n",
    "})\n",
    "\n",
    "print(\"Final Metrics Comparison\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9738a6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "POLICY BEHAVIOR COMPARISON\n",
      "============================================================\n",
      "\n",
      "1. APPROVAL RATES:\n",
      "   Baseline (Historical): 100.0%\n",
      "   DL Model:              65.6%\n",
      "   RL Agent:              95.2%\n",
      "\n",
      "2. RISK PROFILE OF APPROVED LOANS:\n",
      "   DL Approved Loans: 34640 loans\n",
      "     → Default Rate: 11.7%\n",
      "     → Avg Reward per Approved Loan: $-416.61\n",
      "\n",
      "   RL Approved Loans: 50306 loans\n",
      "     → Default Rate: 17.9%\n",
      "     → Avg Reward per Approved Loan: $-1406.07\n",
      "\n",
      "3. DECISION DISAGREEMENTS:\n",
      "   Total Agreement: 70.3%\n",
      "   DL Approves / RL Denies: 6 cases\n",
      "   DL Denies / RL Approves: 15672 cases\n",
      "\n",
      "   Impact of RL's 'Risky' Approvals:\n",
      "     → These 15672 loans had avg reward: $-3594.77\n",
      "     → Default rate: 31.7%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Policy Statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"POLICY BEHAVIOR COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "dl_approve_rate = np.mean(dl_actions == 1)\n",
    "rl_approve_rate = np.mean(rl_actions == 1)\n",
    "\n",
    "print(f\"\\n1. APPROVAL RATES:\")\n",
    "print(f\"   Baseline (Historical): 100.0%\")\n",
    "print(f\"   DL Model:              {dl_approve_rate:.1%}\")\n",
    "print(f\"   RL Agent:              {rl_approve_rate:.1%}\")\n",
    "\n",
    "# Risk profile of approved loans\n",
    "dl_approved_mask = (dl_actions == 1)\n",
    "rl_approved_mask = (rl_actions == 1)\n",
    "\n",
    "if np.sum(dl_approved_mask) > 0:\n",
    "    dl_default_rate = np.mean(y_test[dl_approved_mask])\n",
    "    dl_avg_reward_if_approved = np.mean(r_test[dl_approved_mask])\n",
    "else:\n",
    "    dl_default_rate = 0\n",
    "    dl_avg_reward_if_approved = 0\n",
    "\n",
    "if np.sum(rl_approved_mask) > 0:\n",
    "    rl_default_rate = np.mean(y_test[rl_approved_mask])\n",
    "    rl_avg_reward_if_approved = np.mean(r_test[rl_approved_mask])\n",
    "else:\n",
    "    rl_default_rate = 0\n",
    "    rl_avg_reward_if_approved = 0\n",
    "\n",
    "print(f\"\\n2. RISK PROFILE OF APPROVED LOANS:\")\n",
    "print(f\"   DL Approved Loans: {np.sum(dl_approved_mask)} loans\")\n",
    "print(f\"     → Default Rate: {dl_default_rate:.1%}\")\n",
    "print(f\"     → Avg Reward per Approved Loan: ${dl_avg_reward_if_approved:.2f}\")\n",
    "print(f\"\\n   RL Approved Loans: {np.sum(rl_approved_mask)} loans\")\n",
    "print(f\"     → Default Rate: {rl_default_rate:.1%}\")\n",
    "print(f\"     → Avg Reward per Approved Loan: ${rl_avg_reward_if_approved:.2f}\")\n",
    "\n",
    "# Disagreement Analysis\n",
    "print(f\"\\n3. DECISION DISAGREEMENTS:\")\n",
    "print(f\"   Total Agreement: {np.mean(dl_actions == rl_actions):.1%}\")\n",
    "\n",
    "dl_yes_rl_no = np.sum((dl_actions == 1) & (rl_actions == 0))\n",
    "dl_no_rl_yes = np.sum((dl_actions == 0) & (rl_actions == 1))\n",
    "\n",
    "print(f\"   DL Approves / RL Denies: {dl_yes_rl_no} cases\")\n",
    "print(f\"   DL Denies / RL Approves: {dl_no_rl_yes} cases\")\n",
    "\n",
    "# Financial impact of disagreements\n",
    "if dl_no_rl_yes > 0:\n",
    "    mask_risky = (dl_actions == 0) & (rl_actions == 1)\n",
    "    risky_outcomes = r_test[mask_risky]\n",
    "    print(f\"\\n   Impact of RL's 'Risky' Approvals:\")\n",
    "    print(f\"     → These {dl_no_rl_yes} loans had avg reward: ${np.mean(risky_outcomes):.2f}\")\n",
    "    print(f\"     → Default rate: {np.mean(y_test[mask_risky]):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fd9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

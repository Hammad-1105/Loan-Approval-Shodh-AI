{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b65f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import d3rlpy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac319a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "d3rlpy.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afcba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/processed_loans.csv'\n",
    "df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-calculating rewards\n",
    "def calculate_reward(row):\n",
    "    if row['target'] == 0: # Fully Paid\n",
    "        return row['loan_amnt'] * (row['int_rate'] / 100.0)\n",
    "    else: # Default\n",
    "        return -1.0 * row['loan_amnt']\n",
    "\n",
    "df['reward'] = df.apply(calculate_reward, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81fa586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature/Target Split\n",
    "feature_cols = df.drop(columns=['target', 'reward']).columns\n",
    "X = df[feature_cols].values\n",
    "y = df['target'].values\n",
    "rewards = df['reward'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b82d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split (Same seed as before to match Phase 2)\n",
    "X_train, X_test, y_train, y_test, r_train, r_test = train_test_split(\n",
    "    X, y, rewards, test_size=0.30, random_state=SEED, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee966947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale (Crucial: Fit on Train, Transform Test)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d5d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Test Data to Tensors \n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774eb05",
   "metadata": {},
   "source": [
    "# Loading DL & RL models for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21cb7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanDefaultModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LoanDefaultModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.layer3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.relu1(self.layer1(x)))\n",
    "        x = self.dropout2(self.relu2(self.layer2(x)))\n",
    "        x = self.dropout3(self.relu3(self.layer3(x)))\n",
    "        return self.sigmoid(self.output(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184c2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring DL Model\n",
    "dl_model = LoanDefaultModel(X_train.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(dl_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfb832ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181ec2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model.train()\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = dl_model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d80f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-09 14:17.04 [info     ] Signatures have been automatically determined. action_signature=Signature(dtype=[dtype('int64')], shape=[(1,)]) observation_signature=Signature(dtype=[dtype('float64')], shape=[(79,)]) reward_signature=Signature(dtype=[dtype('float64')], shape=[(1,)])\n",
      "2025-12-09 14:17.04 [info     ] Action-space has been automatically determined. action_space=<ActionSpace.DISCRETE: 2>\n",
      "2025-12-09 14:17.04 [info     ] Action size has been automatically determined. action_size=2\n"
     ]
    }
   ],
   "source": [
    "#Loading RL Agent\n",
    "cql = d3rlpy.algos.DiscreteCQLConfig().create(device=\"cpu\") \n",
    "\n",
    "dummy_actions = np.zeros(100, dtype=int)\n",
    "dummy_actions[0] = 1  \n",
    "\n",
    "cql.build_with_dataset(d3rlpy.dataset.MDPDataset(\n",
    "    observations=np.array(X_train_scaled[:100]), \n",
    "    actions=dummy_actions, \n",
    "    rewards=np.zeros(100),\n",
    "    terminals=np.ones(100)\n",
    "))\n",
    "\n",
    "cql.load_model('../models/cql_loan_agent.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c543970",
   "metadata": {},
   "source": [
    "# Divergent Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7061ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Get Predictions on TEST set\n",
    "dl_model.eval()\n",
    "with torch.no_grad():\n",
    "    dl_probs = dl_model(X_test_tensor).numpy().flatten()\n",
    "    # DL Decisions (Using your Optimized Threshold 0.25)\n",
    "    dl_decisions = (dl_probs > 0.25).astype(int) \n",
    "    dl_actions = 1 - dl_decisions # 1=Approve, 0=Deny\n",
    "\n",
    "# RL Decisions (1=Approve, 0=Deny)\n",
    "rl_actions = cql.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d3ecbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Agree on: 70.3% of cases\n"
     ]
    }
   ],
   "source": [
    "# B. Compare\n",
    "agreement = (dl_actions == rl_actions)\n",
    "print(f\"Models Agree on: {np.mean(agreement):.1%} of cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e2f9bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases where DL says APPROVE but RL says DENY: 6\n"
     ]
    }
   ],
   "source": [
    "# C. Find Divergence: DL Approves (1), RL Denies (0)\n",
    "mask_dl_yes_rl_no = (dl_actions == 1) & (rl_actions == 0)\n",
    "divergent_indices = np.where(mask_dl_yes_rl_no)[0]\n",
    "\n",
    "print(f\"Cases where DL says APPROVE but RL says DENY: {len(divergent_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40efa192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divergent Case Study\n",
      "Applicant Index: 687\n",
      "DL Probability of Default: 0.0471 (Safe < 0.25)\n",
      "RL Action: 0 (Deny)\n",
      "Actual Outcome (Target): 0 (1=Default, 0=Paid)\n",
      "Financial Consequence: $6149.50\n"
     ]
    }
   ],
   "source": [
    "# D. Inspect a specific Divergent Case (for the Report)\n",
    "if len(divergent_indices) > 0:\n",
    "    idx = divergent_indices[0]\n",
    "    \n",
    "    print(\"Divergent Case Study\")\n",
    "    print(f\"Applicant Index: {idx}\")\n",
    "    print(f\"DL Probability of Default: {dl_probs[idx]:.4f} (Safe < 0.25)\")\n",
    "    print(f\"RL Action: {rl_actions[idx]} (Deny)\")\n",
    "    print(f\"Actual Outcome (Target): {y_test[idx]} (1=Default, 0=Paid)\")\n",
    "    print(f\"Financial Consequence: ${r_test[idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df52d5",
   "metadata": {},
   "source": [
    "# Estimated Policy Value (EPV) Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33fc9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Rewards for DL Policy\n",
    "dl_rewards = []\n",
    "for i in range(len(X_test)):\n",
    "    if dl_actions[i] == 1: # DL Approved\n",
    "        dl_rewards.append(r_test[i])\n",
    "    else:\n",
    "        dl_rewards.append(0) # DL Denied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e99e2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Rewards for RL Policy\n",
    "rl_rewards = []\n",
    "for i in range(len(X_test)):\n",
    "    if rl_actions[i] == 1: # RL Approved\n",
    "        rl_rewards.append(r_test[i])\n",
    "    else:\n",
    "        rl_rewards.append(0) # RL Denied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3271a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "epv_dl = np.mean(dl_rewards)\n",
    "epv_rl = np.mean(rl_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fede3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Metrics Comparison\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Deep Learning (Model 1)</th>\n",
       "      <th>RL Agent (Model 2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test Set AUC</td>\n",
       "      <td>0.741</td>\n",
       "      <td>N/A (Policy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test Set F1</td>\n",
       "      <td>0.456</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Est. Policy Value (Avg Reward)</td>\n",
       "      <td>$-273.19</td>\n",
       "      <td>$-1339.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Metric Deep Learning (Model 1) RL Agent (Model 2)\n",
       "0                    Test Set AUC                   0.741       N/A (Policy)\n",
       "1                     Test Set F1                   0.456                N/A\n",
       "2  Est. Policy Value (Avg Reward)                $-273.19          $-1339.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Test Set AUC', 'Test Set F1', 'Est. Policy Value (Avg Reward)'],\n",
    "    'Deep Learning (Model 1)': [0.741, 0.456, f\"${epv_dl:.2f}\"],\n",
    "    'RL Agent (Model 2)': ['N/A (Policy)', 'N/A', f\"${epv_rl:.2f}\"]\n",
    "})\n",
    "\n",
    "print(\"Final Metrics Comparison\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9738a6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Policy Optimization for Financial Decision-Making: Deep Learning vs. Offline RL

**Author:** Hammad Shaikh  
**Assessment:** Shodh AI - Machine Learning Internship Task

---

## ğŸ“Œ Executive Summary

This project explores the transition from **predicting credit risk** to **optimizing financial returns**. Using the LendingClub dataset, I developed and compared two distinct AI systems:

1. **Supervised Deep Learning (DL):** Predicts default probability.  
2. **Offline Reinforcement Learning (RL):** Conservative Q-Learning (CQL) agent that optimizes portfolio value.

### ğŸ” Core Finding

The **Optimized Deep Learning Model** outperformed all other policies:

- DL reduced losses by **85%**  
- RL reduced losses by **26%**

This demonstrates that a well-tuned classifier can outperform offline RL when the deny action is safe and well-defined.

---

## ğŸ“Š Key Results

| Strategy | Primary Metric | Approval Rate | EPV (Est. Policy Value) | Net Improvement |
|---------|----------------|----------------|---------------------------|-----------------|
| **Human Baseline** | N/A | 100% | **â€“$1,805** | â€“ |
| **RL Agent (CQL)** | EPV | 95.2% | **â€“$1,339** | **+26%** |
| **DL Model (Tuned)** | AUC / F1 | 65.6% | **â€“$273** | **+85%** |

---

## ğŸ“‚ Repository Structure
```text
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cql_loan_agent.pt                 # Trained RL Agent
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_preprocessing.ipynb       # Cleaning, leakage removal, scaling
â”‚   â”œâ”€â”€ 02_deep_learning.ipynb            # MLP training & threshold optimization
â”‚   â”œâ”€â”€ 03_offline_rl.ipynb               # Reward engineering & CQL training
â”‚   â””â”€â”€ 04_analysis_and_comparison.ipynb  # Final EPV & policy comparison
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ Hammad_Shaikh_Report_Shodh_AI.pdf
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Hammad-1105/Loan-Approval-Shodh-AI.git
cd Loan-Approval-Shodh-AI
```

### 2ï¸âƒ£ Create environment (conda or venv)

**Conda:**
```bash
conda create -n shodh_ai python=3.9
conda activate shodh_ai
```

**Venv:**
```bash
python -m venv venv
source venv/bin/activate      # Mac/Linux
venv\Scripts\activate         # Windows
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ“ Data Setup

**Download:**
```text
accepted_2007_to_2018.csv
```

**Place it in:**
```text
data/accepted_2007_to_2018.csv
```

---

## ğŸš€ How to Run the Code (Reproducibility Steps)

Run notebooks in this exact order:

### âœ… 1. Data Preprocessing

**ğŸ“Œ `01_data_preprocessing.ipynb`**

- Removes leakage features
- Removes missing-heavy columns
- Encodes categories, scales numerics
- Performs correlation filtering

**Output:** `cleaned_data.csv`

---

### âœ… 2. Deep Learning Model

**ğŸ“Œ `02_deep_learning.ipynb`**

- Trains PyTorch MLP (256â†’128â†’64)
- Handles class imbalance
- Tunes threshold to 0.25

**Reproduced Metrics:**

- AUC = 0.741
- F1 = 0.456
- EPV â‰ˆ â€“$273

---

### âœ… 3. Offline RL Training (CQL)

**ğŸ“Œ `03_offline_rl.ipynb`**

- Adds counterfactual Deny actions
- Defines reward model
- Trains CQL via d3rlpy

**Reproduced Metrics:**

- Approval Rate: 95.2%
- EPV: â€“$1,339

---

### âœ… 4. Analysis & Comparison

**ğŸ“Œ `04_analysis_and_comparison.ipynb`**

- Computes EPV for all policies
- Compares DL vs RL
- Extracts divergence cases
- Recreates Applicant #45 case

---

## ğŸ“Œ Reproducibility Notes

Running the four notebooks sequentially will reproduce:

- All metrics in the report
- EPV values
- Threshold tuning behavior
- RL agent decisions
- Divergent case study outputs

---